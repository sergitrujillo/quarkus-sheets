:icons: font
== Chapter 3 - Rest Services with Quarkus with Mongo together

=== Requisites

To be done Part 1 and Part 2.

=== Configuring Quarkus project

You need to install extension to quarkus in order to get driver to connect to mongo.

[source,shell script]
----
$ ./mvnw quarkus:add-extension -Dextensions="io.quarkus:quarkus-mongodb-client"
----

We need to configure IP and port by using mongo url connection to our project (https://docs.mongodb.com/manual/reference/connection-string/).
You need to open an existing resource file `application.properties`.
And set this url by setting new property named `quarkus.mongodb.connection-string`.

[source]
----
quarkus.mongodb.connection-string = mongodb://localhost:27017`
----

=== Changing Repository

You get profit to early implementation of PersonsRepository.
This implementation has a list on it storage persons.
Now, we change this to storage persons in a collection of mongo.
While we implement new storage we remove all list references.

To get a mongo client we only need to inject this:

[source,java]
----
@Inject MongoClient mongoClient;
----

We need to access to a collection mongo object.
Create a new private method to get access to collection.

[source,java]
----
private MongoCollection<Document> getCollection() {
    return mongoClient.getDatabase("quarkus-test").getCollection("persons", Document.class);
}
----

The default system to storage data is by Document objects that we need to convert.
In next steps we can do this more easily.
We do add and getAll methods as a demonstration of managing documents.

Mongo by default primary key is defined by _id attribute of documents this is a hex string representation.
We need change this types in order to access objects by this id.
For instance we change int to String of key representation.

[source,java]
----
public String add(Person person) {
    Document document = new Document()
        .append("name", person.getName())
        .append("surname", person.getSurname());
    getCollection().insertOne(document);
    return document.getObjectId("_id").toString();
}

public List<Person> getAll() {
    return StreamSupport
        .stream(getCollection().find().spliterator(), false)
        .map(this::convert)
        .collect(Collectors.toList());
}

private Person convert(Document document) {
    Person p = new Person();
    p.setName(document.getString("name"));
    p.setSurname(document.getString("surname"));
    return p;
}
----

We can do it with some help using Codecs of mongo.
With this the conversion to Document could be almost automatic.
We need to change getCollection method with defining object Person and add a codec registry.

[source,java]
----
private CodecRegistry getCodecRegistry() {
    CodecProvider pojoCodecProvider = PojoCodecProvider.builder()
        .conventions(Arrays.asList(Conventions.ANNOTATION_CONVENTION))
        .register(Person.class)
        .automatic(true).build();
    return fromRegistries(MongoClientSettings.getDefaultCodecRegistry(), fromProviders(pojoCodecProvider));
}
private MongoCollection<Person> getCollection() {
    return mongoClient.getDatabase("quarkus-test")
        .getCollection("persons", Person.class)
        .withCodecRegistry(getCodecRegistry());
}
----

In order to get information of key of object we need to add this to model.
Using annotations of mongo codec helpers we mark what attribute is the primary key.
We use a String as a primary key because we don’t like to implement an autoincrement control, instead of that we use a generated UUID as a primary key

[source,java]
----
@BsonId
private String id;
----

Add getters and setters and change all references of int by String.

[source,java]
----
public void add(Person person) {
    person.setId(UUID.randomUUID().toString());
    getCollection().insertOne(person);
}

public List<Person> getAll() {
    return StreamSupport
        .stream(getCollection().find().spliterator(), false)
        .collect(Collectors.toList());
}

public Optional<Person> get(String id) {
    return StreamSupport
        .stream(getCollection().find()
        .filter(Filters.eq("_id", id)).spliterator(), false)
        .findAny();
}


public Optional<Person> replace(String id, Person person) {
    getCollection().replaceOne(Filters.eq("_id", id), person);
    return get(person.getId());
}

public Optional<Person> remove(String id) {
    Optional<Person> person = get(id);
    getCollection().deleteOne(Filters.eq("_id", id));
    return person;
}
----

You could observe that primary key in mongo is stored with _id key.
For this reason we need find with this key instead of that we have defined in our model.

We need to make some changes in PersonsService class and we can do all tests that we had done with List in-memory implantation.

[source,java]
----
@GET
@Produces(MediaType.APPLICATION_JSON)
public List<Person> getAll() {
    return personsRepository.getAll();
}

@GET
@Path("{id}")
@Produces(MediaType.APPLICATION_JSON)
public Person get(@PathParam("id") String id) {
    return personsRepository.get(id)
        .orElseThrow(NotFoundException::new);
}

@POST
@Consumes(MediaType.APPLICATION_JSON)
@Produces(MediaType.APPLICATION_JSON)
public Response add(Person person, @Context UriInfo uriInfo) {
    personsRepository.add(person);
    UriBuilder builder = uriInfo.getAbsolutePathBuilder();
    builder.path(person.getId());
    return Response.created(builder.build()).build();
}

@PUT
@Path("{id}")
@Consumes(MediaType.APPLICATION_JSON)
@Produces(MediaType.APPLICATION_JSON)
public Person replace(@PathParam("id") String id, Person person) {
    return personsRepository.replace(id, person)
        .orElseThrow(NotFoundException::new);
}

@DELETE
@Path("{id}")
@Produces(MediaType.APPLICATION_JSON)
public Person remove(@PathParam("id") String id) {
    return personsRepository.remove(id)
        .orElseThrow(NotFoundException::new);
}
----

==== Adding pagination to getAll

Unlike in-memory example when we like to get a subset of results it's better that database manage this, so that we needn't
load all record and after filter with streams. For this reason we pass to repository skip and limit and manage with database query.

.Changed PersonService
[source,java]
----
@GET
@Produces(MediaType.APPLICATION_JSON)
public List<Person> getAll(@QueryParam("limit") @DefaultValue("10") int limit,
                           @QueryParam("skip") @DefaultValue("0") int skip) {
    return personsRepository.getAll(skip, limit);
}
----

.Changed PersonsRepository
[source,java]
----
public List<Person> getAll(int skip, int limit) {
    return StreamSupport
        .stream(getCollection().find().skip(skip).limit(limit).spliterator(), false)
        .collect(Collectors.toList());
}
----

=== Jointly Mongo and Quarkus on Docker

In this case we use docker-compose utility.
This utility help us to run two containers: one with database and other with our services created with quakus and manage internal connection with both containers.
This utility require and a file with YAML format that declares all that we want.

Create `docker-compose.yml` file on you project home path.
And add this content:

[source,yaml]
----
version: '3'
services:
  quarkus:
    build: .
    environment:
      - quarkus.mongodb.connection-string=mongodb://mongodb:27017
    ports:
      - "8080:8080"
    links:
      - mongodb
    depends_on:
      - mongodb
  mongodb:
    image: mongo:latest
    container_name: mongodb
    environment:
      - MONGO_DATA_DIR=/data/db
    volumes:
      - ./data/db:/data/db
    ports:
      - 27017:27017
----

CAUTION: Yaml files is so important you maintain indentation with 2 spaces.

This file describes 2 services.
In quarkus we indicat that build self (it use Dockerfile that we have created before ).
We configure url of mongo (this use dns name that we set as service name) and exposes ports, finally it says that this depends on mongo service and for this reason system always start after mongo service is available.
Next Mongo service we define witch image we like to use and configure a volume that we like to store database files.
In this example we map database port in order to access externally with compass, but it’s not necessary for running system.

When we have this file we need to build and start this.
(Ensure that other mongo o service in your system are stopped otherwise this fails because the ports get conflict).

[source,shell script]
----
$ docker-compose build
$ docker-compose up
----

Now you can do all test: get, post, put and delete data with our service as we had done before.

If you want to stop press `Ctrl + C` on your terminal.
And, if you want to remove containers you can delete it:

[source,shell script]
----
$ docker-compose down
----

Docker and docker-compose have a huge number of options you could get more information on their reference webpages:

https://docs.docker.com/
https://docs.docker.com/compose/reference/